[{"authors":["An Nguyen","Christina Yoong","Jasmine Kim"],"categories":null,"content":"Please visit the SIG 3 Google Site to get started!\n","date":1573365600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573365600,"objectID":"938b4bd36feffb1ba8d93efac7b82bce","permalink":"https://colig.github.io/laumn/post/week11/","publishdate":"2019-11-10T00:00:00-06:00","relpermalink":"/laumn/post/week11/","section":"post","summary":"SIG 3.","tags":["Tools","Data"],"title":"SIG3: Multimodal Learning Analytics","type":"post"},{"authors":["Khomson Keratithamkul","Hong Shui","Corbin Rice"],"categories":null,"content":" 1. Read and annotate Read an introductory paper on Text/Discourse analytics to familiarize yourself with the topic.\n Chapter 7: Content analytics: The definition, scope, and an overview of published research  When you read this chapter, annotate anything that will be helpful to you. Consider: What aspect or finding from this article could you possibly bring to and incorporate in your project or work place?\n2. Introductory video Here is a short video to introduce you to text mining.\n What is text mining?  3. More reading Choose one of the two readings to read and annotate.\n 1) Computational Grounded Theory: A Methodological Framework (in PDF) 2) Computational Methods to Extract Meaning From Text and Advance Theories of Human Cognition (in PDF)  When reading the article, think about how content analysis mentioned in this article be used in your working group project. Specifically, how could content an alysis be used in your working group project?\n4. Application Choose a text analysis tool to analyze our Hypotheses annotations. It could be annotations from one week, one person, a SIG or WG, etc. Please share your findings, learning journey, or challenges on Slack.\n AcaWriter\n Cohmetrix\n LIWC\n KH coder 3\n   Google Cloud Natural Language API\n qdap\n  See you all in Zoom on Monday, November 11th!\n","date":1572847200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572847200,"objectID":"c63274de736258866a61cb7987a9b08c","permalink":"https://colig.github.io/laumn/post/week10/","publishdate":"2019-11-04T00:00:00-06:00","relpermalink":"/laumn/post/week10/","section":"post","summary":"SIG 2 on Text and Discourse Analytics.","tags":["Text Mining","Discourse Analytics"],"title":"Week 10: Content and Text Analytics (SIG 2)","type":"post"},{"authors":[],"categories":null,"content":" ","date":1567746000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567746000,"objectID":"e8eef06b575f2e199c6a1b20456e1ccd","permalink":"https://colig.github.io/laumn/post/glossary/","publishdate":"2019-09-06T00:00:00-05:00","relpermalink":"/laumn/post/glossary/","section":"post","summary":"A crowd-sourced glossary of the community.","tags":["Glossary"],"title":"Glossary","type":"post"},{"authors":null,"categories":null,"content":" This week, we will be diving into Social Network Analysis as an approach to studying the exchange of information. Social network analysis looks at various patterns of relationships between different actors and examines the availability and exchange of resources between them (Scott, 1991; Wasserman \u0026amp; Faust, 1994). The actors exchanging resources and information could be individuals or organizations and their relationships determine the kind of information exchanged.\nHere is a short video to help you through the definition of social network analysis better.\n Plan and Resources this Week: 1. Read \u0026amp; annotate  Grunspan et al. (2017). A primer that introduces how an SNA research project can be done in education. Chen et al. (2018). A case study of building an analytic tool based on SNA for student sense-making.  Consider the following questions as you read the articles about SNA:\n What are the key elements of an SNA project based on the Grunspan et al. (2017) article? What tools do you notice the authors using for SNA? What considerations are needed when applying SNA in teaching practice? How do you see SNA being of use to your WG project?  As we continue to work on WG projects, please keep in mind your group tags when annotating. By doing so, we will be able to index our ideas as we continue to engage with all sorts of resources.\n2. Explore social network analysis tools Gephi Gephi is an open-source network analysis tool based on Java. To explore Gephi, check out one or more of the following resources:\n Gephi.org Overview of Gephi  Gephi: Making your relational data very pretty \u0026ndash; This tutorial is kind of long, but it uses sample data to explore many of the features of Gephi. The Complete n00b’s Guide to Gephi \u0026ndash; This article breaks down how to start using Gephi. It’s a nice simple resource to get started.   Download Gephi (from gephi.org) and explore the features it has. The download comes with sample data using characters from Les Miserables. The video tutorial linked above uses that data to demonstrate many of the features of Gephi. If you’re unable to use Gephi on your personal computer, you might consider connecting with a classmate who is able to use it successfully. Note: You may need to download/update Java on your computer.\nIf you have any issues or questions as you’re exploring this tool, please reach out to your colleagues on Slack.\nR or Python If R is your go-to \u0026ldquo;Swiss Army knife\u0026rdquo; for data analysis, check out one of the packages such as igraph, sna, and statanet.\nIf you prefer Python, check out networkx or igraph.\nOther network analysis tools Some of you have taken my SNA class (CI 8371) and please consider exploring other novel network analysis tools.\n Using Gephi, you can analyze dynamic networks. Epistemic Network Analysis (ENA) is a method for identifying and quantifying connections among elements in coded data and representing them in dynamic network models. A key feature of the ENA tool is that it enables researchers compare different networks, both visually and through summary statistics that reflect the weighted structure of connections. Exponential random graph models (ERGMs) is a family of statistical models for analyzing networks . See tutorial. statnet provides a suite of packages for analyzing temporal networks. See tutorial.  3. Use data from Hypothes.is annotations to make a visualization 3.1. Data wrangling challenge First, use the Hypothesis data exporting tool to extract some sample data from our group. You will need to access your API token here if you wish to export data from your private groups. Please choose the CSV format as it is the most helpful format for this activity.\nTransform the exported data to a format that works for Gephi or a tool of your choice. Consult with the first reading and Gephi tutorials for information about acceptable formats.\nPlease feel free to share your cleaned data on Slack and to help each other.\n3.2. Network analysis challenge Import the data into Gephi (or a tool of your choice) and create a visualization of our interactions.\nYou can also play with other functions such as computing centrality measures and detecting communities in our group.\nBe prepared to share your adventures during our Zoom meeting on Monday, November 4th!\n","date":1540702800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572325200,"objectID":"2861b9aa3d28196d91682b3a79c90214","permalink":"https://colig.github.io/laumn/post/week9/","publishdate":"2018-10-28T00:00:00-05:00","relpermalink":"/laumn/post/week9/","section":"post","summary":"SIG 1 on Social Network Analysis.","tags":["Tools","Data"],"title":"Week 9: Social Networks (SIG 1)","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Data wrangling, or data munging, is a critical part of any learning analytics project. It covers multiple components of the Learning Analytics Model including the collection, storage, cleaning, and integration of data (see Siemens 2013, which we read in Week 1).\nDue to the quantity of data and the diversity of data sources, a learning analytics project often necessicitates data wrangling \u0026ndash; conducted by humans \u0026ndash; in order to transform data into actionable intelligence and systematic action (Clow, 2012).\nThis week, we will:\n Familiarzie with the concept of data wrangling Play with at least one data-wrangling tool of your choice Share your data-wranglinge experiences with peers Draft a data-wrangling plan with your Working Group members  What is data wrangling? According to Wikipedia:\n Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \u0026ldquo;raw\u0026rdquo; data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. A data wrangler is a person who performs these transformation operations.\n Over the past years, I have seen polls of data scientists (like this one) showing they spend 60% of their time \u0026lsquo;massaging\u0026rsquo; instead of analyzing data. This percentage may even go up to 80-90% in some reports.\n“90% of data science is wrangling data, the other 10% is complaining about wrangling data.”@evelgab at #rstatsnyc\n\u0026mdash; David Robinson (@drob) April 20, 2018 \nPlan and Resources This Week As each Working Group project starts to take shape, this week provides each group an opportunity to consider the data aspect and draft a Data Wrangling plan for the project.\nBelow are activities designed for this week.\n1. Watch a lecture on data wrangling This lecture was delivered by Tony Hirst to the Data, Analytics and Learning MOOC in 2014. Tony is an active blogger, and his blog has always been a great source of inspiration for me.\n 2. Play with one data wranging tool of your choice Our choices include \u0026ndash; but are not limited to \u0026ndash; the following:\nSpreadsheets. Yes, spreadsheets (e.g. Excel, Google Sheets) are incredibly powerful when it comes to data wrangling. Below are two tutorials that may help you unleash the power of spreadsheets.\n School of Data: A Gentle Introduction to Data Cleaning Data Carpentry: Data Organization in Spreadsheets   OpenRefine, formerly Google Refine, \u0026ldquo;is a powerful tool for working with messy data: cleaning it; transforming it from one format into another; and extending it with web services and external data.\u0026rdquo; Its official website provides several introductory videos to get you started. There is a Data Capentry course on OpenRefine for Social Science Data.\nDataiku Data Science Studio (DSS). A data science workbench that provides a Graphical User Interface (GUI) similar to OpenRefine. I\u0026rsquo;ve recorded a tutorial video (of an earlier version) to demonstrate its usefulness for data wrangling. More tutorials can be found on its official website.\n R and RStudio. If you know R basics, I strongly encourage you to spend some time on the tidyverse ecosystem. It has absolutely transformed my data wrangling practices in R.\n RStudio webinar on data wrangling Lynda.com course on Data wrangling with R and RStudio  Python, another popular programming language among data scientists. There are plenty of tutorioals out there. Below are just two examples.\n Wrangling data with Pandas Wrangle Data in Jupyter Notebooks with PixieDust Rosie  This list is by no means exhaustive or comprehensive. Is there a data wrangling tool you like? Let us know by leaving a Hypothesis annotation here!\nFinally, check out the Data Carpentry website that offers a range of lessons and workshops that you may find useful.\n3. Share your journey as a Data Wrangler via Slack Yes, we can do it! How did your journey go? Have you discovered your data-wrangling superpower? Share a blurb about your journey in the #2019-general channel of Slack. If you choose to blog your experience, please post a link to your blog post to the #2019-general Slack channel.\nIf you encounter data wrangling challenges, please also feel free to share on Slack so that we can problem solve together.\n4. Discuss a data-wrangling plan with your Working Group What implications does this week\u0026rsquo;s work have on your Working Group project? Discuss with your group members anywhere you like (e.g. Slack,F2F, Zoom). Please add your data-wrangling ideas to your project space on Knowledge Forum.\nHousekeeping for Formal Participation Our next Zoom meeting is on Oct 28.\nThe first SIG Session will happen on Nov 4. Details will be posted on Oct 29.\nEnjoy digging and wrangling!\n","date":1540184400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571720400,"objectID":"51c0b7f6b55eb7e2d7e1c699fc8c14aa","permalink":"https://colig.github.io/laumn/post/week8/","publishdate":"2018-10-22T00:00:00-05:00","relpermalink":"/laumn/post/week8/","section":"post","summary":"Consider the data pipeline and play with data wrangling tools.","tags":["Tools","Data"],"title":"Week 8: 'All About Data,' Data Wrangling","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Over the past few weeks, we have explored multiple dimensions of Learning Analytics \u0026ndash; ethical, epistemological, conceptual/theoretical, pedagogical, technical \u0026ndash; and have devleoped nuanced understanding of this field. Bringing together perspectives from distinctive disciplines into meaningful conversations takes time. I\u0026rsquo;m proud of our collective work so far in the community!\nWeek 7 Plan and Resources This week, we will make use of what we\u0026rsquo;ve learned so far to identify and analyze cases/examples of learning analytics applications.\nTwo talks Before we dive into identifying and analyzing cases, I want to share two talks that are related to this week and the projects you are working on.\nThe first talk was given by Prof. Stephanie Teasley from the University of Michigan, a powerhouse of learning analytics research \u0026amp; practice. She is a past president of SoLAR and has been leading various learning analytics efforts at UMich, including the My Learning Analytics (MyLA) project to be rolled out at UMN. Her talk, titled \u0026ldquo;Learning Analytics: Data Science for Education\u0026rdquo;, covers many grounds including analytics tool design and evaluation.\n The second talk was an ACM TechTalk delivered by Prof. Joseph Konstan from our own University of Minnesota. This talk, titled \u0026ldquo;Recommender Systems: Beyond Machine Learning\u0026rdquo;, is more technical and of special interest to those of you interested in adaptive learning and educational recommender systems. Below are the slides [in PDF]. To watch the talk, you will need to fill out the registration form near the bottom of this ACM page, which will direct you to a recorded webinar.\n Case analysis After watching these videos, please conduct a learning analytics case analysis following these two main steps.\n1: Identify Ideally, you will identify minimally one case/example pertinent to your Working Group project.\nI am providing only a few examples below but you should absolutely go beyond this list.\n Course Signals: EDUCAUSE article, LAK12 video ECoach: http://ai.umich.edu/portfolio/e-coach/ Academic Writing Analytics: https://utscic.edu.au/tools/awa/ My Learning Analytics (MyLA): https://sites.google.com/umich.edu/my-learning-analytics-help/home Yellowdig visualization tool: https://vimeo.com/169580885  2. Analyze When analyzing a case/example, please consider the following aspects:\n   Aspects of the project Your analysis     Name and links    Context and stakeholders    Project goals    Learning constructs    Data sources    Data analysis/mining techniques    Actions suggested or taken    Ethical considerations     To contribute your analysis, please make a Hypothesis Page Note on a webpage about the analyzed case/example. Not sure how to make a Page Note? See the screenshot below or the help page for details. Of course, you can make regular Hypothesis annotations as well when engaging with the web document. As always, you are strongly encouraged to use WG or SIG related tags so that your annotations are informing your evolving projects. You are also encouraged to comment on each other\u0026rsquo;s analysis.\nPro Tip: You can copy-and-paste the Markdown code below to make a table in your annotation. The number of characters betwee each pair of |s won\u0026rsquo;t matter.\n| Aspects of the project/application | Analysis | |------------------------------------|----------| | Name and links | | | Context and stakeholders | | | Project goals | | | Learning constructs | | | Data sources | | | Data analysis/mining techniques | | | Actions taken or suggested | | | Ethical considerations | |  Housekeeping for Formal Participation Since we\u0026rsquo;ve finalized our Working Group and Special Interest Group plans, please make use of Knowledge Forum, Slack channels, and other collaboration tools to coordinate with each other.\nGroup project is never easy! UMN has some very useful tips to make sure your group project will not look like \u0026ldquo;the zombie apocalypse\u0026rdquo;.\nHave a great week!\n","date":1539579600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571029200,"objectID":"fe926499fe9d641b4851ee4f3480c418","permalink":"https://colig.github.io/laumn/post/week7/","publishdate":"2018-10-15T00:00:00-05:00","relpermalink":"/laumn/post/week7/","section":"post","summary":"An opportunity to explore example learning analytics applications.","tags":["Cases","Examples"],"title":"Week 7: Cases and Examples of Learning Analytics","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" As a sister field of Learning Analytics, Educational Data Mining (EDM) emerged a few years earlier and has its own disciplinary identity (e.g., a stonger computer science focus, its own professional society, conference, and journal). While two communities developed separately in the beginning, communication and collaboration between two communities (PDF) have increased over the years.\nThe overlaps and differences between two communities are nicely summarized by Siemens (2013):\n Where LA is more concerned with sensemaking and action, educational data mining (EDM) is more focused toward developing methods for \u0026ldquo;exploring the unique types of data that come from educational settings\u0026rdquo;. Although the techniques used are similar in both fields, EDM has a more specific focus on reductionist analysis (Siemens \u0026amp; Baker, 2012). As LA draws from and extends EDM methodologies (Bienkowski, Feng, \u0026amp; Means, 2012, p. 14), it is a reasonable expectation that the future development of analytic techniques and tools from both communities will overlap.\n We are diving into EDM this week by exploring its connections with LA and playing with various data mining tools used in both communities.\nWeek 6 Readings  Baker, R. S., \u0026amp; Inventado, P. S. (2014). Educational Data Mining and Learning Analytics. In J. A. Larusson \u0026amp; B. White (Eds.), Learning Analytics: From Research to Practice (pp. 61–75). New York, NY: Springer New York. Slater, S., Joksimović, S., Kovanovic, V., Baker, R. S., \u0026amp; Gasevic, D. (2017). Tools for Educational Data Mining: A Review. Journal of Educational and Behavioral Statistics, 42(1), 85–106.  As we start to work on our SIGs and WGs, it would be great to think about making some of your annotations more useful for your group projects. I encourage each group to use your group tag, e.g., #SIG_multimodal, #WG_recommender_system. By doing so, we will be able to index our ideas as we continue to engage with all sorts of resources.\nNote: These tags need to used accurately (e.g. spaces and caps matter) in order to be nicely aggregated by Hypothes.is.\nHousekeeping Projects Since we\u0026rsquo;ve finalized our Working Group and Special Interest Group plans, please create channels on Slack, invite group members in, and create group workspaces on Knowledge Forum (KF).\nLet the party begin!\nNext meetings I strongly encourage you attend the Inaugural Learning Informatics Seminar on Oct 23, featuring Simon Buckingham Shum. RSVP here!\nOur next virtual meeting will take place on Monday, Oct 28, 5-6:30pm via Zoom. You should have received a Calendar invitation with details.\n","date":1538974800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570424400,"objectID":"ec3de8400171ab3b16712261ce128d84","permalink":"https://colig.github.io/laumn/post/week6/","publishdate":"2018-10-08T00:00:00-05:00","relpermalink":"/laumn/post/week6/","section":"post","summary":"A brief introduction to Educational Data Mining (EDM) as a sister field of LA, as well as popular EDM tools.","tags":["EDM","Techniques"],"title":"Week 6: Educational Data Mining: An Overview","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" In this week, we will extend our dialogues on learning theory in Week 4 into deeper conversations about hidden assumptions in learning analytics.\nThis line of thinking has been informed by a talk given by Simon Knight at LAK13 titled Epistemology, Pedagogy, Assessment and Learning Analytics (see slides below). Their work has evolved over the years and one reading for this week is a book chapter with a set of provocations pushing us to think more about hidden assumptions.\n I\u0026rsquo;ve written about this topic as well, but in my mother tongue Chinese. To me, \u0026ldquo;Learning Analytics is like an iceberg. Its visible parts include materialized tools and observable activities, while its hidden parts comprise conceptualizations of learning, power relations in teaching and learning, and complex social, political and cultural intentions of education.\u0026rdquo; Catering to the Chinese audience, I drew on the etymology of the character 数 (\u0026ldquo;number\u0026rdquo;) in Chinese and explained how one of its ancient forms (below) is embedded with the meaning of punishing a woman for her \u0026ldquo;mistakes\u0026rdquo;. I could not stop asking: to what extent is this original meaning still reflected in our use of numbers or data (数据) today? Which other assumptions and biases are built into our daily data practices in general and learning analytics in particular? How about other languages or cultures?\nWeek 5 Readings  Knight \u0026amp; Buckingham Shum. (2017). Handbook of Learning Anlaytics, Chpater 1. Perrotta, C., \u0026amp; Williamson, B. (2018). The social life of Learning Analytics: cluster analysis and the “performance” of algorithmic education. Learning, Media and Technology, 43(1), 3–16.  As we work towards forming our SIGs and WGs, it would be great to think about making some of your annotations more useful for your group projects. I encourage each group to come up with a group tag, e.g., #SIG_social_network, #WG_recommender_system. By doing so, we will be able to index our ideas as we continue to engage with all sorts of resources.\nAs I explained in our Zoom meeting last week, you will be able to drag and drop your Hypothesis annotations into Knowledge Forum when you collaboratively work on your projects. The following animation gives you some sense about the process, but you can also drag an annotation directly into a note you\u0026rsquo;re editing.\nSIG and WG Project Planning First of all, please finalize your Working Group (WG) and Special Interest Group (SIG) choices. Feel free to ask questions on Slack.\nIf you have assembled a group, congratulations! As for next steps, I suggest you consider the following when launching your SIG and WG efforts:\n On Knowledge Forum, create a new view dedicated to your group (SIG or WG). You can configure your view to be private, protected, or public. In your WG view, start crafting your project idea. You can copy earlier discussions over or start from scratch. Use it as a shared workspace to organize your work. Of course, you can use other tools like Google docs. But one benefit of using KF is it is less linear and interface with Hypothesis. In your SIG view, start planning the session you will lead. Feel free to reach out to Bodong for reading suggestions.  Housekeeping Our next virtual meeting will take place on Monday, Oct 7, 5-6:30pm via Zoom. You should have received a Calendar invitation with details.\n","date":1538370000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569819600,"objectID":"f0a73bd2f28bd0e31922ad46c3e20578","permalink":"https://colig.github.io/laumn/post/week5/","publishdate":"2018-10-01T00:00:00-05:00","relpermalink":"/laumn/post/week5/","section":"post","summary":"Learning analytics is like an iceberg, with a myriad of assumptions hidden under the water.","tags":["Theory"],"title":"Week 5: Hidden Assumptions: Epistemology, Pedagogy, and Assessment","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Learning analytics are about learning, so theories of learning should not be ditched despite the data deluge that has been fueling the growth of learning analytics. Since the dawn of the field, there have been voices arguing for the importance of learning theory in the design, development, and implementation of learning analytics. In 2015, a special section was published by the Journal of Learning Analytics on the relation between learning theory and learning analytics. In the guest editorial, Wise and Shaffer (2015, p. 5) write:\n It is an exhilarating and important time for conducting research on learning, with unprecedented quantities of data available. There is danger, however, in thinking that with enough data, the numbers speak for themselves. In fact, with larger amounts of data, theory plays an ever-more critical role in analysis.\n The notion that theory matters even more in \u0026ldquo;big data\u0026rdquo; research in education goes against what was proposed in a controversial Wired article titled \u0026ldquo;The end of theory: The data deluge makes the scientific method obsolete\u0026rdquo; (Anderson, 2008). Now there is little disagreement that learning theory is essential for learning analytics.\nBriefly speaking, there are essentially two ways theory is important for the field of learning analytics.\n1. Theory Use in Learning Analytics As a field of research and practice, learning analytics work naturally draws from all sorts of theories. As summarized by Wise and Shaffer (2015, p. 9):\n Theory gives a researcher guidance about which variables to include in a model Theory gives a researcher guidance about what potential confounds, subgroups, or covariates in the data to account for Theory gives a researcher guidance as to which results to attend to Theory gives a researcher a framework for interpreting results Theory gives a researcher guidance about how to make results actionable Theory helps a researcher generalize results to other contexts and populations  For example, self-regulated learning (SRL) is widely used in learning analytics and MOOC research. SRL as a learning theory has informed data collection, data transformation, data mining, and result interpretation.\n2. Theory Building in Learning Analytics Even more exciting to me is the possibility of building new theories of learning and teaching, based on fine-grained data analysis enabled by advanced computational methods. Learning analytics and educational data mining research could give rise to new theories. For example, whether keystroke analysis can shed light on our understanding of writing processes? Whether temporal analysis can uncover \u0026ldquo;productive\u0026rdquo; patterns of collaborative discourse?\nEqually valuable are theories of learning analytics usage in emerging socio-technical contexts. For example, as new learning analytics tools are put in the hands of instructors to aid their pedagogical decisions, domain theories of analytics use can be created (e.g., van Leeuwen, 2015).\nWeek 4 Readings This week\u0026rsquo;s readings speak in particular to theory use in learning analytics. Reading #1 is a guest editorial on temporal analysis of learning data, which discusses four critical issues that are applicable to all learning analytics work. Reading #2 provides a concrete example of using a well-established learning theory (self-regulated learning in this case) in a research study. Reading #3 (optional) is the controversial Wired article mentioned above.\n Chen, B., Knight, S., \u0026amp; Wise, A. F. (2018). Critical Issues in Designing and Implementing Temporal Analytics. Journal of Learning Analytics, 5(1), 1–9. (Note: Only Sections 3-4 (pp. 3-7) are required.) Kizilcec, R. F., Pérez-Sanagustín, M., \u0026amp; Maldonado, J. J. (2017). Self-regulated learning strategies predict learner behavior and goal attainment in Massive Open Online Courses. Computers \u0026amp; Education, 104, 18–33. (Note: This file is accessible via the UMN Libraries.) Optional: Anderson, 2008, The End of Theory: The Data Deluge Makes the Scientific Method Obsolete  When reading each required article, please create at least 1 annotation and reply to 2 annotations made by peers. When interacting with Reading #2, please note how the self-regulated learning theory was applied in the study. Please use tags intentionally in your annotations to help you retrieve ideas potentially useful for our group projects.\nMeet Learning Analytics Experts Dr. Alyssa Wise is Associate Professor of Learning Sciences and Educational Technology and the Director of the Learning Analytics Research Network at NYU. She is an Editor in Chief of the Journal of Learning Analytics and an Associate Editor of the Journal of the Learning Sciences. According to her bio, \u0026ldquo;Dr. Wise\u0026rsquo;s research is situated at the intersection of the learning sciences and educational data science, focusing on the design of learning analytics systems that are theoretically grounded, computationally robust, and pedagogically useful for informing teaching and learning.\u0026rdquo; Among many wise things shared by Dr. Wise, below is a recent video clip of her talking about what we need to be successful in the field of learning analytics. She is also scheduled to deliver a webinar on Oct 16 2019 about Designing Learning Analytics for Humans with Humans.\n Dr. David Williamson Shaffer is the Vilas Distinguished Professor of Learning Sciences at the University of Wisconsin-Madison. He is known for his work on game-based learning and Epistemic Network Analysis. Below is a keynote speech he delivered at the 2018 Learning Analytics and Knowledge conference in Sydney, where he summarized his idea of \u0026ldquo;quantitative ethonography\u0026rdquo; and ways to tackle theory scarcity in the age of \u0026ldquo;big data.\u0026rdquo;\n Housekeeping Please continue to explore and articulate your Working Group project ideas on Knowledge Forum. Please consider problems/goals, stakeholders, data sources, analysis, and action of your group project. Feel free to team up!\nPlease explore and consolidate your Special Interest Group (SIG) choice. Feel free to ask questions on Slack if you\u0026rsquo;re unsure about any SIG topics.\nPlease note that the deadline for group signup is Week 5.\n","date":1537765200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569301200,"objectID":"02330958f979bbbbc751fd4593fa52ce","permalink":"https://colig.github.io/laumn/post/week4/","publishdate":"2018-09-24T00:00:00-05:00","relpermalink":"/laumn/post/week4/","section":"post","summary":"Learning analytics are about learning, so theories of learning should not be ditched despite the data deluge that has been fueling the growth of learning analytics.","tags":["Theory"],"title":"Week 4: Theory and Learning Analytics","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Let\u0026rsquo;s be clear, ethics should not be an after-thought in a learning analytics application. But what do ethical practices in the field entail is not always clear.\nWhile research ethics considers principles such as confidentiality, privacy, and informed consent, a learning analytics project may not be considered research at all (if its goal is not to produce generalizable knowledge). However, extensive collection of learning data, increasing cases of \u0026ldquo;black-box algorithms,\u0026rdquo; and more direct impact on learners necessitate some serious conversations about ethics in learning analytics.\nLast week\u0026rsquo;s discussions have already touched upon many questions about ethics. This week, we are going to dive into ethics, algorithmic accountability, and system integrity.\nWeek 3 Readings  Prinsloo, P., \u0026amp; Slade, S. (2017). Ethics and Learning Analytics: Charting the (Un)Charted. In C. Lang, G. Siemens, A. Wise, \u0026amp; D. Gasevic (Eds.), Handbook of Learning Analytics (Chapter 4, pp. 49–57). Society for Learning Analytics Research (SoLAR). (Note: It may be difficult to highlight larger text snippets in this particular PDF file.) Choose one from the following two:  Kitto, K., \u0026amp; Knight, S. (2019). Practical ethics for building learning analytics. British Journal of Educational Technology. Please annotate this Open Access version. Chen, B., \u0026amp; Zhu, H. (2019). Towards Value-Sensitive Learning Analytics Design. Proceedings of the 9th International Conference on Learning Analytics \u0026amp; Knowledge, 343–352. Please annotate this Open Access version.   When reading each article, please create at least 1 annotation and reply to 2 annotations made by peers.\nMeet Learning Analytics Experts Paul Prinsloo from the University of South Africa (Unisa) has been writing and giving talks about \u0026lsquo;ethics and learning analytics\u0026rsquo; for many years. He has recently delivered a keynote on this topic in Scotland. He has graciously allowed me to embed his slides on our course website:\nZombie categories, broken data and biased algorithms: What else can go wrong? Ethics in the collection, analysis and use of student data  \nSimon Buckingham Shum, Director of the Connected Intelligence Centre (CIC) at the University of Technology Sydney, invited us to consider \u0026lsquo;Algorithmic Accountability\u0026rsquo; and \u0026lsquo;Analytic System Integrity\u0026rsquo;. Discussion of Algorithmic Accountability has been taken up by important academic associations like the Association for Computing Machinery (ACM). But Simon stretches our thinking to consider \u0026lsquo;Analytic System Integrity\u0026rsquo; in learning analytics. Below is a talk he gave at the UCL Institute of Education in 2016. His team is recently working on Ethical Design Critique, which offers concrete measures to enhance ethics in learning analytics tools. (And he is scheduled to visit UMN this October! Details soon.)\n \u0026ldquo;Living\u0026rdquo; with Learning Analytics Last week, we introduced CROWD LAAERS designed for Hypothes.is.\nThis week, I encourage you to explore KF\u0026rsquo;s list of analytic tools (see below) that can be accessed via the Assessment button. They are developed by colleagues from various countries. Note that we\u0026rsquo;re using the newest version of KF and colleagues are still revamping many of these analytic tools based on earlier versions. So they are not always user-friendly. If you have ideas that can make them better, consider turning your ideas into a course project and I will try to connect you with the right colleagues to realize your ideas.\nHousekeeping Continuing to Consider Groups Please continue to explore and articulate your Working Group project ideas. Please consider problems/goals, stakeholders, data sources, analysis, and action of your project. Continue to comment on each other\u0026rsquo;s ideas on KF and don\u0026rsquo;t be shy about saying \u0026ldquo;Our ideas are like cousins. Let\u0026rsquo;s team up.\u0026rdquo;\nPlease start to consider which Special Interest Group(s) you\u0026rsquo;re interested in. Below is a list of tentative topics but you can suggest topics beyond the list. Ideally, the Special Interest Group you sign up for is related to your Working Group project.\n Social Network Analysis Predictive Models Text and Discourse Analytics Visual Learning Analytics Temporal Analytics Institutional Readiness  Virtual Meeting Our next virtual meeting will take place on Monday, 09/23, 5-6:30pm via Zoom. You will receive a Calendar invitation with details.\n","date":1537074000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568610000,"objectID":"360c0e50cc89c96df36cf579c9b69617","permalink":"https://colig.github.io/laumn/post/week3/","publishdate":"2018-09-16T00:00:00-05:00","relpermalink":"/laumn/post/week3/","section":"post","summary":"Ethics, algorithmic accountability, and system integrity in learning analytics","tags":["Ethics","Algorithmic Accountability"],"title":"Week 3: Ethics, Algorithmic Accountability, and System Integrity","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Thanks for the engaged conversations in the first week of #LAUMN!\nWe\u0026rsquo;ve been engaged in such thoughtful dialogues via Hypothes.is, Slack, and Zoom. As we try to survive all those acronyms, here is a community glossary you can look at and contribute to.\nWhat is apparent to myself is that the breadth of expertise represented in our community is truly energizing. I hope we can continue to have deep conversations within and beyond this community, and to engage in learning that\u0026rsquo;s personal to everyone of us.\nIn the spirit of \u0026ldquo;living and exploring the capacity of learning analytics\u0026rdquo; (see the Syllabus), I want to introduce an analytics tool named CROWD LAAERS developed by my UC-Denver colleagues Remi Kalir and Francisco Perez for the Marginal Syllabus project. This application, which just came out last year, retrieves annotations from the server and generates interesting interactive visualizations.\nFor instance, after authenticating yourself using your Hypothes.is API token, you will be able to choose our group and have a bird-eye view of our annotation activities. I found the Threads section quite useful for discovering threads with more (or less) participation. You can click on a particular thread to filter the data.\nAnother example is the calendar view that tells us when we tend to make annotations.\nIt appears we were quite busy making annotations during the weekend. I believe we can do better next week \u0026ndash; working less during the weekend if possible ;-)\nWeek 2 This week we will:\n Develop a stronger grasp of the field of LA Start to explore Working Group project ideas  Video After reading and discussing the George Siemens (2013) article during Week 1, it\u0026rsquo;s worthwhile to watch a lecture George gave to a MOOC (massive open online course) on learning analytics. George is the founding president of the Society for Learning Analytics Research (SoLAR), which is the most prominent international organization of learning analytics.\n (Note: Great questioning during Week 1 on whether the definition(s) of learning analytics have changed over the years. I encourage you to keep this question alive as we dig into more readings, interact with scholars like George on Twitter, or tweet such questions to the #LearningAnalytics hashtag.)\nReadings This week, we will get a chance to take a closer look at this field by exploring more cases/examples and posing more questions. What problems do learning analytics seek to address? In which educational settings? At which levels of an education system? Because this field is truly inter- and trans-disciplinary, I expect us to enter this field from our unique backgrounds and contribute to the field with different perspectives.\n Buckingham Shum, S. (2012). UNESCO Policy Brief: Learning Analytics. UNESCO Institute for Information Technologies in Education. Choose one from below (Note: #1 is open-access, and #2 is accessible to UMN colleagues):  Bienkowski, M., Feng, M., \u0026amp; Means, B. (2012). Enhancing Teaching and Learning Through Educational Data Mining and Learning Analytics: An issue brief (pp. 1-35). U.S. Department of Education Office of Educational Technology. Krumm, A., Means, B., \u0026amp; Bienkowski, M. (2018). Learning Analytics Goes to School: A Collaborative Approach to Improving Education, Chapter 2. Routledge. (Note: This reading can only be annotated offline. Check this Youtube video to learn how.)   When reading each article, please create at least 1 annotation and reply to 2 annotations made by peers. Let the community know when you find a case that matches perfectly with your interests, stretches your imagination of learning analytics, or concerns you for whatever reasons.\nThis week, I encourage you to be very intentional about tags you use in Hypothesis annotations. Several ground rules I\u0026rsquo;d like to propose to our collective tagging to help us better index our ideas:\n Let\u0026rsquo;s include # in our tags (e.g., #question) Let\u0026rsquo;s use lowercase (e.g., #sharing), unless the tag is a named entity (e.g., #LMS) Let\u0026rsquo;s not include spaces, but use underscore (_) instead (e.g., #data_mining instead of #data mining)  Reminder: If you are a UMN participant, when annotating with Hypothes.is, please make sure the LAUMN-2019 group is selected. If you are not sure about annotating PDFs, please refer back to tutorials in Week 1.\nExploring Working Group project ideas While/after reading, draft a project idea based on your interests and post it on Knowledge Forum. At this point, it is totally okay if your project idea is more or less vague. This is an opportunity for us to learn more about our interests, receive feedback, and form project teams.\nAfter posting your project idea, please read and build on each other\u0026rsquo;s contributions if you\u0026rsquo;re also interested or have questions/suggestions.\nNot sure how to create or build on a Knowledge Forum contribution, watch this video tutorial (note the UI may look different as we\u0026rsquo;re using a more recent version of the software):\n Pro tip: In Knowledge Forum, you will see a searchable list of Hypothesis annotations from our community. You can either drag an annotation to form a new note, or drag an annotation into an existing note. You can use this feature if your project idea is grounded in the readings.\nBelow are a list of example project ideas. Please see the syllabus for more detailed guidelines.\n Applying Natural Language Processing to Investigating Language Development and Epistemic Complexity in Group Chats Integrating a Teacher Dashboard in K-12: A Mixed-Methods Study of Teacher Perspectives \u0026ldquo;Burn the World\u0026rdquo; Learning Analytics Design (Note: Burn the World is a game for environmental education.) \u0026ldquo;The Bridge\u0026rdquo;: An Analytics Tool to Integrate Community Knowledge on StackOverflow in RStudio Developing a Deep Learning Model for the Prediction of Student Success in Introductory Physics  Virtual Meeting We will NOT meet synchronously this week. Our next virtual meeting will take place on Monday, 09/23, 5-6:30pm via Zoom. You will receive a Calendar invitation with details.\nSee you soon!\n","date":1536555600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568091600,"objectID":"5999033742e12cfc5b155986d8daa287","permalink":"https://colig.github.io/laumn/post/week2/","publishdate":"2018-09-10T00:00:00-05:00","relpermalink":"/laumn/post/week2/","section":"post","summary":"What problems does learning analytics seek to address? In which educational settings? At which levels of an education system?","tags":["Overview","Video"],"title":"Week 2: Learning Analytics: A Brief Overview","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" A warm welcome to CI 5371 - Learning Analytics: Theory and Practice! I am so excited to offer this course again this fall at the University of Minnesota. As the instructor, I learn so much from the class community each year and look forward to our adventure together this semester!\nThis week we will:\n Get familiar with the course, including its design, schedule, and tools Get to know each other Read an introductory article Discuss our diverse interests in learning analytics  The Course Syllabus First thing first, please read the course syllabus in its entirety. Leave a comment or send me an email when you have any questions.\nTechnology setup An online course does not need to be about watching videos and answering quizzes. To foster rich learning experiences, we will be using several technological tools to foster social, collaborative learning. Depending on your familiarity with these tools, there could be a learning curve. So please spend time this week to familiarize yourself with them.\nZoom. We will host a number of virtual meetings on Zoom throughout the semester. Please make sure your computer has Zoom installed (see the video below). Please test your Zoom setup in advance to make sure audio and video configurations work properly. You will receive a calendar invitation with details about joining our Zoom meetings.\n Slack. You will receive a link that invites you to join our Slack community. Course announcements are made on Slack. All sorts of class discussion will take place there as well. You can also interact with course alums in some public channels.\nFirst time using Slack? Watch the video below and/or read this brief introduction to Slack.\n Hypothes.is. If you\u0026rsquo;re a formal participant, you should have received a link that invites you to join our Hypothes.is group. Hypothes.is is a web annotation tool that enables us to discuss readings in a contextual manner. When annotating, please make sure our group name (LAUMN-2019) is properly selected. See this page to get started, and this page to learn about annotating together as a group.\nKnowledge Forum (KF). If you\u0026rsquo;re a formal participant, you should have received a link and a registration key to join our Knowledge Forum community. KF is a space for collaborative knowledge building. It\u0026rsquo;s where we propose our initial (and sometimes naive) ideas and then grow them this semester. KF has a suite of analytics tools as well, so it will allows us to \u0026lsquo;live\u0026rsquo; the capacity of learning analytics while we explore this topic.\n Two tracks of participation This course website is openly available, allowing two tracks of participation designed for this class.\n UMN class: For UMN graduate students enrolled in the class, your participation in this class is not that different from taking another online class. You are expected to meet course requirements outlined in the course syllabus. You will have private spaces (on Slack and Hypothesis private group) for within-class communications. You can decide the extent to which you interact with colleagues outside of the class list. Open participation: For \u0026lsquo;Open Participants\u0026rsquo; who would like to follow along, you can access the same materials curated on this website. Because 90% of course readings are open-access, you will be able to annotate readings using Hypothes.is as well (using the LAUMN tag). You are also encouraged to interact with me and community members via Twitter hashtag #LAUMN.  If you have any feedback on the design, I\u0026rsquo;d love to hear your thoughts.\nWeek 1 Readings  Course syllabus Siemens, G. (2013). Learning analytics: The emergence of a discipline. The American Behavioral Scientist, 57(10), 1380–1400. (Downloadable PDF for Open Participants.)  When reading Siemens (2013), please create at least 1 annotation and reply to 2 annotations made by peers. Not sure what/how to annotate, consider sentence starters like: \u0026quot;I'm intrigued by...\u0026quot;, \u0026quot;I'm surprised by...\u0026quot;, \u0026quot;I need to understand...\u0026quot;, \u0026quot;Additional resource...\u0026quot;, etc.\nTip: Click on the Annotations link to the top of this page to see all annotations posted to our Hypothes.is group.\nVirtual Meeting Our first virtual meeting will take place on Monday, 09/09, 5-6:30pm via Zoom. You will receive a Calendar invitation with details.\nSee you soon!\n","date":1535518800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567486800,"objectID":"9f2799f01ef07323bca16fbf22a3bd29","permalink":"https://colig.github.io/laumn/post/week1/","publishdate":"2018-08-29T00:00:00-05:00","relpermalink":"/laumn/post/week1/","section":"post","summary":"Getting started with CI 5371.","tags":["Introduction"],"title":"Week 1: Introduction","type":"post"},{"authors":[],"categories":null,"content":" ","date":1533099600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533099600,"objectID":"d05a050b8b35b6f1eedc60980c7a79e5","permalink":"https://colig.github.io/laumn/post/annotations/","publishdate":"2018-08-01T00:00:00-05:00","relpermalink":"/laumn/post/annotations/","section":"post","summary":"Web annotations made by the community.","tags":["Tools","hide"],"title":"Web Annotations","type":"post"}]