[{"authors":["Valerie Barbaro"],"categories":null,"content":" Last week we had the opportunity to learn about text/discourse analytics and play with Acawriter, a writing analytics tool. This week we will be extending our knowledge of text analytics by exploring the \u0026ldquo;machine behind the curtain.\u0026rdquo; Topics this week will include the text mining process as well as the AI that enables text mining to function.\nHere is a short video to help ground you in the basics of text mining:\n 1. Read \u0026ldquo;The Seven Practice Areas of Text Analytics\u0026rdquo; (Giner et al., 2012). This book chapter defines types of text mining and provides an overview of the text mining process. Because the selection is from a book, it references other book sections that cover specific text mining approaches. We will dig into some of these approaches our other resources.\nTo facilitate both your WG project and our class discussion, annotate as usual with #GoodPoints, #UsefulPoints, and #MuddyPoints. We will be using FROG this week for our discussion.\n2. Optional: Watch video on how machine learning works. This optional video (~10 mins) describes how machine learning\u0026ndash;a form of AI that can be used in texting mining\u0026ndash;works. While optional, the video is fun and approachable, and it can serve as a useful foundation for learning the terms and concepts you\u0026rsquo;ll encounter in the resources listed in #3.\n 3. Pick your poison to learn some related terms and concepts You can opt to read the article or watch 2 videos below. The article covers a wider variety of topics but is perhaps a bit denser (i.e., there are some formulas in it, but don\u0026rsquo;t let those scare you). The videos cover fewer definitions but go more in depth with the ones they do include.\nRead \u0026ldquo;Text Mining: Techniques and Its Applications\u0026rdquo; (Allahyari et al., 2017).\nOR\nWatch these 2 videos:\n  Note: To annotate a video, you can use VideoAnt, a resource developed right here at UMN. Instructions for how to annotate are included on the VideoAnt page. You can export your annotations by clicking on the gear within your videoant and selecting the export option. You may find it helpful to annotate using our same 3 tags, though these won\u0026rsquo;t be available for FROG.\nConsider the following questions as you explore the resources:  What is text mining, what is machine learning, and how are they related? What are the benefits of using machine learning (or other AI) for mining text? What are the drawbacks? How might you use text mining or machine learning (or other AI) for your WG project or in your research in general?  4. Text Mining Play Using Voyant Voyant is an open-source text mining/analytics tool you likely will find very user friendly. In fact, it\u0026rsquo;s so user friendly, there is no downloading or installing. Simply copy and paste your text or a url into the box, press the Reveal! button, and voila\u0026ndash;Voyant does the rest!\nVoyant\u0026rsquo;s tools for exploring are fairly intuitive, but you may find it helpful to watch a brief overview that describes the basic tools or watch a more detailed tutorial to get into the nitty-gritties of the tools.\nWe will briefly share our explorations during discussion on Monday, November 26. 5. Identify an Additional Text Mining/Text Analytics or Machine-learning Tool of Your Choice Identify 1 additional text mining/analytics or machine-learning tool that might be helpful in your research. To do this, review tools we\u0026rsquo;ve discussed in class or your annotations from Week 6\u0026rsquo;s \u0026ldquo;Tools for Educational Data Mining\u0026rdquo;, or find a different tool using a resource like this. You could also opt to explore what it would involve to create your own text-mining or machine-learning tool (using R or Python, for example).\nPlease note that identifying does not mean fully exploring the tool. The purpose of this exercise is to (re)familiarize yourself with a tool that you perhaps expressed interest in sometime during our course, and to give you a structured opportunity to learn a bit more about it.\nOnce you\u0026rsquo;ve identified a tool, write a brief paragraph (or bulleted list) that addresses the following:  What tool did you choose and what are its main functions? How would you use the tool for your research? What do you like about the tool? What are its limitations? What is it lacking, or what do you find frustrating about it?  Be prepared to share your findings in discussion on Monday, November 26. We will be applying what you learned during an exercise in class.\nEnjoy learning about the machine behind the curtain this week!\nIf you have any issues or questions, please reach out to your colleagues on Slack.\nP.S.: Think machine learning is super cool and want to learn more? Consider checking out this video series on deep learning.\n","date":1542520800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542520800,"objectID":"77c26622fa7f43b2b71f0979c1ffae6a","permalink":"https://colig.github.io/laumn/post/week12/","publishdate":"2018-11-18T00:00:00-06:00","relpermalink":"/laumn/post/week12/","section":"post","summary":"SIG 4 on text mining, text analytics, and AI.","tags":["Tools","Data"],"title":"Week 12: The machine behind the curtain: Text mining, text analytics, and AI","type":"post"},{"authors":["Chloe Stricklin","Sarah Barksdale","Julie Pokaski","Tayler Loiselle"],"categories":null,"content":" 1. Read and annotate “Chapter 7: Content Analytics: The Definition, Scope, and an Overview of Published Research” (Kovanović et al., 2017) from Handbook of Learning Analytics.\nWe recommend reading this article first, as it provides a nice introduction to the area of text/content analytics as part of the larger LA field. The authors also give an overview of several important studies that have implications for the future of content analytics.\n2. Read and annotate “Reflective Writing Analytics for Actionable Feedback” (Gibson et al, 2017), which is a case study that aimed to provide students with actionable feedback through an analytics program created by the Academic Writing Analytics project.\nSince we will be using FROG in our class session, please tag your annotations for the two articles with “UsefulPoints,” “GoodPoints,” or “MuddyPoints” to keep track of topics relevant to your WG.\n3. After completing the readings, consider the following reflection questions. You will then be typing your answers into the AcaWriter tool discussed below:\n How have the readings changed and/or confirmed your thoughts about content analytics? Please provide specific examples. If you have had prior experience with content analytics, also share what that looked like, any difficulties you experienced, and outcomes you achieved. How do you think content analytics may (or may not) fit into your professional context? What challenges might you encounter? What insights might it provide? Reflect on how content analytics may be useful for your Working Group. Why would it be a good fit, or why not?\n  As you prepare your responses, keep in mind the developed “Reflection Framework” in order to make the most of the content analysis tool:\n4. Play around with a text analysis tool! Write your answers to the reflection questions in AcaWriter (a program created by the Academic Writing Analytics project), and review the feedback that you receive from the tool. We recommend writing at least 3-4 complete sentences for each question, using reflective language (e.g. “I think,” “I feel,” “I was challenged by,” “I now know,” etc.), and choosing the “Reflective Standard” option in the “Genre” drop-down menu in order to maximize the tool’s effectiveness.\nMake sure to save your answers and the feedback, as we will be sharing these in class. Feel free to share any other text/discourse analysis tools you have used and your experiences with them via Slack!\n5. Optional Reading: If you engage with social media regularly (for professional, educational, or personal use), or are just interested, the following article provides a computational discourse method to make meaning of social media (SM) data. The article discusses “a methodology to analyze and visualize streams of Social Media messages, and [applies] it to a case in which Twitter is used as a backchannel, i.e. as a communication medium through which participants follow an event in the real world as it unfolds.”\nLipizzi, C., Dessavre, D., Iandoli, \u0026amp; Ramirez Marquez, J. (2016). Towards computational discourse analysis: A methodology for mining Twitter backchanneling conversations. Computers in Human Behavior, 64, 782-792.\nIf you have any questions or comments, please reach out to our SIG leaders on Slack.\n","date":1541656800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1541656800,"objectID":"938b4bd36feffb1ba8d93efac7b82bce","permalink":"https://colig.github.io/laumn/post/week11/","publishdate":"2018-11-08T00:00:00-06:00","relpermalink":"/laumn/post/week11/","section":"post","summary":"SIG 3 on Text and Discourse Analytics.","tags":["Text Mining","Discourse Analytics"],"title":"Week 11: Text and Discourse Analytics (SIG 3)","type":"post"},{"authors":["Neal Fredrickson \u0026 Matt Vernon"],"categories":null,"content":" \u0026ldquo;All models are wrong; some are useful\u0026rdquo; By the end of this week we hope that you will be able to better understand and explain this quote. This week, we will be surveying predictive modeling in education using a combination of readings and tools to work with data. Let\u0026rsquo;s get started!\nPlan and Resources for this Week: 1. Take this quick survey 2. Readings  Required: Brooks and Thompson. Handbook of Learning Technologies Chp 5. “ Predictive Modelling in Teaching and Learning\u0026rdquo; Choose one additional reading:  Manuel Ekowo and Iris Palmer, Oct 2016. \u0026ldquo;The promise and peril of predictive analytics in higher education\u0026rdquo; Steven Tang, Joshua C. Peterson \u0026amp; Zachary A. Pardos, 2017.\u0026ldquo;Predictive Modeling of Student Behavior Using Granular Large-Scale Action Data\u0026rdquo;   Annotate as usual with “good points, useful points, muddy points.” We won’t be using FROG this week, but you can use these tags to keep track of points relevant for your WG.\n3. Consider the following questions as you read the articles about Predictive Modeling:  How is predictive modeling different than explanatory modeling? What common issues are confronted in collecting data? How can that influence feature selection and algorithm choice in the model? What is involved in testing and evaluating a model, why can\u0026rsquo;t it be ignored in the process? What would be an example of second order predictive modeling that you would be interested in?  Optional Video Extras These might be helpful to you, they were to me!\n 2min video “6 steps of predictive modeling with machine learning\u0026rdquo; CrashCourse \u0026ldquo;Correlation≠Causation\u0026rdquo;  Play Time 4. Model building tools and data sets. Weka is described as a \u0026ldquo;machine learning workbench\u0026rdquo; it has a straightforward GUI and is open source. This tool runs on PC, Mac \u0026amp; Linux. I am running on a Mac but does require java, so if you run into install issues that\u0026rsquo;s most likely the culprit. Reach out on slack if you do.\n Step 1 Download and install Weka Step 2 Watch this video and follow along on how to load data sets, select features, classify, compare results, evaluate and test a model. Optional Challenge Activity! Format and create a model for your own data set Use this blog post to learn how to create a WEKA formatted file to use with the program. Rank the features sets to determine which attributes are useful.  5. Prep for Zoom meeting. Guided Practice. Neal has created an analysis tool in google sheets and supplied it with data. Your task is two identify two models using the tool and data to share with your small group.\n Step 1 Make a copy of the spreadsheet in google docs. Step 2 Watch Neal take you through the steps of making predictions using the tool.   This is survey data retrieved from students in CI5301 “Foundations of Computer Applications for Business and Education.” Students responded to questions at the beginning and at the end of the semester to measure their change in digital literacies (website building skills, information management,\nscreencasting, etc\u0026hellip;)\n More Context about the Data Students answered the following questions on a 1-5 Likert-type scale. 1 = very low skill, 5 = very high skill. The data presented here is the difference between their self ratings at the end of the semester and their self ratings at the beginning of the semester. That is, these numbers represent their “growth” or “change” in ratings over the course of the semester.\nPredictor Variables (Independent Variables)\n dWebDes: “How proficient are you with Web Design for professional purposes?” dSiteMap: “How proficient are you with Concept / Site Mapping for professional purposes?” dScreencast: “How proficient are you with Screencasting for professional purposes?” dVideoHost: “How proficient are you with Video Hosting for professional purposes?” dVideoConference: “How proficient are you with Video Conferencing for professional purposes?” dInfoMgt: “How proficient are you with Information Management for professional purposes?” dProjectMgt: “How proficient are you with Project Management for professional purposes?” dCollaboration: “How proficient are you with Collaboration Tools for professional Purposes?” dGraphDes: “I know how to apply graphic design concepts to creating aesthetically-pleasing digital media products.” dSelfLearn: “I know how to learn a new computer program on my own using instructional videos and resources on the web.” dProblemSolve: “I know how to apply appropriate technological solutions to real-world problems.” Female: 1 = female; 0 = male. Athlete: 1 = student athlete; 0 = not student athlete  OutcomeVariables (Dependent Variables)\n ParticipationGrade: Student grade for first major project out of 100 possible points Project1Grade: Student grade for pitch major project out of 100 possible points Project2Grade: Student grade for website major project out of 100 possible points Project3Grade: Student grade for webinar major project out of 100 possible points FinalGrade: Student final grade. Final grade = (Participation + Project 1 + Project 2 + Project 3) / 400 x 100  If you have any issues or questions, please reach out to your colleagues on Slack. ","date":1540702800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540789200,"objectID":"c63274de736258866a61cb7987a9b08c","permalink":"https://colig.github.io/laumn/post/week10/","publishdate":"2018-10-28T00:00:00-05:00","relpermalink":"/laumn/post/week10/","section":"post","summary":"SIG 2 on Predictive modeling and predictive analytics.","tags":["Tools","Data"],"title":"Week 10: Predictive Modeling (SIG 2)","type":"post"},{"authors":["Crystal Rose-Wainstock","Nicholas Spase","Rukmini Manasa Avadhanam","Angelina Constantine"],"categories":null,"content":" This week, we will be diving into Social Network Analysis as an approach to study the exchange of information. Social network analysis looks at various patterns of relationships between different actors and examines the availability and exchange of resources between them (Scott, 1991; Wasserman \u0026amp; Faust, 1994). The actors exchanging resources and information could be individuals or organizations and their relationships determine the kind of information exchanged.\nHere is a short video to help you through the definition of social network analysis better.\n Plan and Resources this Week: 1. Read Grunspan et al. (2017) Annotate as usual with “good points, useful points, muddy points.” We won’t be using FROG this week, but you can use these tags to keep track of points relevant for your WG.\n2. Choose one additional reading and annotate as usual  Topîrceanu, 2017 Oshima, Oshima, \u0026amp; Matsuzawa, 2012 Penuel, Riel, Krause \u0026amp; Frank, 2009  3. Consider the following questions as you read the articles about SNA:  What are the key elements of the Grunspan, Wiggins, and Goodreau article? How do you see these emerge (or not) in your chosen additional reading? What tools do you notice the authors from your two articles using for Social Network Analysis? How do you see Social Network Analysis being of use to your Working Group project?  4. Explore a social network analysis tool According to Wikipedia, Gephi is an open-source network analysis tool that uses Java. To explore Gephi, check out one or more of the following resources:\n Gephi.org Overview of Gephi  Gephi: Making your relational data very pretty \u0026ndash; This tutorial is kind of long, but it uses sample data to explore many of the features of Gephi. The Complete n00b’s Guide to Gephi \u0026ndash; This article breaks down how to start using Gephi. It’s a nice simple resource to get started.   Download Gephi (from gephi.org) and explore the features it has. The download comes with sample data using characters from Les Miserables. The video tutorial linked here uses that data to demonstrate many of the features of Gephi. If you’re unable to use Gephi on your personal computer, you might consider connecting with a classmate who is able to use it successfully. Note: you may need to download/update Java on your computer.\nIf you have any issues or questions as you’re exploring this tool, please reach out to your colleagues on Slack.\n5. Use data from Hypothes.is annotations to make a visualization Use data collected and prepared from annotations from four articles this semester to explore the features of Gephi a little bit more. There are two .csv files you will need to use Gephi. One file is the nodes (people) from our class, and the other is the edges (relationships/interactions). The edges are undirected.\nImport the data into Gephi and create a visualization of our interactions in these four articles. Be prepared to share your visualizations during our discussion on Monday, November 5th!\n","date":1540702800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540789200,"objectID":"2861b9aa3d28196d91682b3a79c90214","permalink":"https://colig.github.io/laumn/post/week9/","publishdate":"2018-10-28T00:00:00-05:00","relpermalink":"/laumn/post/week9/","section":"post","summary":"SIG 1 on Social Network Analysis.","tags":["Tools","Data"],"title":"Week 9: Social Network Analysis (SIG 1)","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Data wrangling, or data munging, is a critical part of any learning analytics project. It covers multiple components of the Learning Analytics Model including the collection, storage, cleaning, and integration of data (see Siemens 2013, which we read in Week 1).\nDue to the quantity of data and the diversity of data sources, a learning analytics project often necessicitates data wrangling \u0026ndash; conducted by humans \u0026ndash; in order to transform data into actionable intelligence and systematic action (Clow, 2012).\nThis week, we will:\n Familiarzie with the concept of data wrangling Play with at least one data-wrangling tool of your choice Share your data-wranglinge experiences with peers Draft a data-wrangling plan with your Working Group members  What is data wrangling? According to Wikipedia:\n Data wrangling, sometimes referred to as data munging, is the process of transforming and mapping data from one \u0026ldquo;raw\u0026rdquo; data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics. A data wrangler is a person who performs these transformation operations.\n Over the past years, I have seen polls of data scientists (like this one) showing they spend 60% of their time \u0026lsquo;massaging\u0026rsquo; instead of analyzing data. This percentage may even go up to 80-90% in some reports.\n“90% of data science is wrangling data, the other 10% is complaining about wrangling data.”@evelgab at #rstatsnyc\n\u0026mdash; David Robinson (@drob) April 20, 2018 \nPlan and Resources This Week As each Working Group project starts to take shape, this week provides each group an opportunity to consider the data aspect and draft a Data Wrangling plan for the project.\nBelow are activities designed for this week.\n1. Watch a lecture on data wrangling This lecture was delivered by Tony Hirst to the Data, Analytics and Learning MOOC in 2014. Tony is an active blogger, and his blog has always been a great source of inspiration for me.\n 2. Play with one data wranging tool of your choice Our choices include \u0026ndash; but are not limited to \u0026ndash; the following:\nSpreadsheets. Yes, spreadsheets (e.g. Excel, Google Sheets) are incredibly powerful when it comes to data wrangling. Below are two tutorials that may help you unleash the power of spreadsheets.\n School of Data: A Gentle Introduction to Data Cleaning Data Carpentry: Data Organization in Spreadsheets   OpenRefine, formerly Google Refine, \u0026ldquo;is a powerful tool for working with messy data: cleaning it; transforming it from one format into another; and extending it with web services and external data.\u0026rdquo; Its official website provides several introductory videos to get you started. There is a Data Capentry course on OpenRefine for Social Science Data.\nDataiku Data Science Studio (DSS). A data science workbench that provides a Graphical User Interface (GUI) similar to OpenRefine. I\u0026rsquo;ve recorded a tutorial video (of an earlier version) to demonstrate its usefulness for data wrangling. More tutorials can be found on its official website.\n R and RStudio. If you know R basics, I strongly encourage you to spend some time on the tidyverse ecosystem. It has absolutely transformed my data wrangling practices in R.\n RStudio webinar on data wrangling Lynda.com course on Data wrangling with R and RStudio  Python, another popular programming language among data scientists. There are plenty of tutorioals out there. Below are just two examples.\n Wrangling data with Pandas Wrangle Data in Jupyter Notebooks with PixieDust Rosie  This list is by no means exhaustive or comprehensive. Is there a data wrangling tool you like? Let us know by leaving a Hypothesis annotation here!\n3. Share your journey as a Data Wrangler via Slack Yes, we can do it! How did your journey go? Have you discovered your data-wrangling superpower? Share a blurb about your journey in the #general channel of Slack.\nFor Open Participants, please tweet under the #LAUMN hashtag.\n4. Discuss a data-wrangling plan with your Working Group What implications does this week\u0026rsquo;s work have on your Working Group project? Discuss with your group members anywhere you like (e.g. Slack, Zoom, F2F).\nHousekeeping for Formal Participation There will be no Zoom meeting on Oct 29 to provide us more \u0026lsquo;play time\u0026rsquo;.\nThe first SIG Session on Social Networks will happen on Nov 5. Details will be posted on Oct 29.\nEnjoy digging!\n","date":1540184400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1540184400,"objectID":"51c0b7f6b55eb7e2d7e1c699fc8c14aa","permalink":"https://colig.github.io/laumn/post/week8/","publishdate":"2018-10-22T00:00:00-05:00","relpermalink":"/laumn/post/week8/","section":"post","summary":"Consider the data pipeline and play with data wrangling tools.","tags":["Tools","Data"],"title":"Week 8: 'Fun with Data' Hands-on","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Over the past few weeks, we have explored multiple dimensions of Learning Analytics \u0026ndash; ethical, epistemological, conceptual/theoretical, pedagogical, technical \u0026ndash; and have devleoped nuanced understanding of this field. Bringing together perspectives from distinctive disciplines into meaningful conversations takes time. I\u0026rsquo;m proud of our collective work so far in the community!\nThanks to information shared by Crystal, I attended a panel named \u0026ldquo;Big Data and the Future of Social Research\u0026rdquo; organized by the College of Liberal Arts. Many points made by the panelists resonated with myself and are in line with what we\u0026rsquo;ve been discussing in the community. I especially appreciated panelists\u0026rsquo; thoughts on challenges with \u0026ldquo;big data\u0026rdquo; projects (my tweet below). I anticipate we will wrestle with these challenges as well in the next couple of weeks.\nChallenges with #BigData research shared by the panel:\n1) linking different data sources; 2) communication within an interdisciplinary team (building shared vocab, willing to make conceptual/methodological shifts); 3) ethical challenges even for ancient records @umncla\n\u0026mdash; ʙᴏᴅᴏɴɢ ᴄʜᴇɴ (@bod0ng) October 11, 2018 \nWeek 7 Plan and Resources This week, we will make use of what we\u0026rsquo;ve learned so far to identify and analyze cases/examples of learning analytics applications.\n1: Identify Ideally, you will identify minimally one case/example pertinent to your Working Group project.\nI am providing a few examples below but you should absolutely go beyond this list.\n Course Signals: EDUCAUSE article, LAK12 video ECoach: http://ai.umich.edu/portfolio/e-coach/ Academic Writing Analytics: https://utscic.edu.au/tools/awa/ Yellowdig visualization tool: http://sites.northwestern.edu/teachx2016/2016/01/26/gru/  2. Analyze When analyzing a case/example, please consider the following aspects:\n   Aspects of the project Analysis     Name and links    Context and stakeholders    Project goals    Learning constructs    Data sources    Data analysis/mining techniques    Actions suggested or taken    Ethical considerations     To contribute your analysis, please make a Hypothesis annotation on a webpage about the analyzed case/example. Please be prepared to introduce the case during our Zoom meeting. Feel free to comment on each other\u0026rsquo;s analysis.\nPro Tip: You can copy-and-paste the Markdown code below to make a table in your annotation. The number of characters betwee each pair of |s won\u0026rsquo;t matter.\n| Aspects of the project/application | Analysis | |------------------------------------|----------| | Name and links | | | Context and stakeholders | | | Project goals | | | Learning constructs | | | Data sources | | | Data analysis/mining techniques | | | Actions taken or suggested | | | Ethical considerations | |  Housekeeping for Formal Participation Since we\u0026rsquo;ve finalized our Working Group and Special Interest Group plans, please create channels on Slack and invite group members in.\nHave a great week!\n","date":1539579600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1539579600,"objectID":"fe926499fe9d641b4851ee4f3480c418","permalink":"https://colig.github.io/laumn/post/week7/","publishdate":"2018-10-15T00:00:00-05:00","relpermalink":"/laumn/post/week7/","section":"post","summary":"An opportunity to explore example learning analytics applications.","tags":["Cases","Examples"],"title":"Week 7: Cases and Examples of Learning Analytics","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" As a sister field of Learning Analytics, Educational Data Mining (EDM) emerged a few years earlier and has its own disciplinary identity (e.g., a stonger computer science focus, its own professional society, conference, and journal). While two communities developed separately in the beginning, communication and collaboration between two communities (PDF) have increased over the years.\nThe overlaps and differences between two communities are nicely summarized by Siemens (2013):\n Where LA is more concerned with sensemaking and action, educational data mining (EDM) is more focused toward developing methods for \u0026ldquo;exploring the unique types of data that come from educational settings\u0026rdquo;. Although the techniques used are similar in both fields, EDM has a more specific focus on reductionist analysis (Siemens \u0026amp; Baker, 2012). As LA draws from and extends EDM methodologies (Bienkowski, Feng, \u0026amp; Means, 2012, p. 14), it is a reasonable expectation that the future development of analytic techniques and tools from both communities will overlap.\n We are diving into EDM this week by exploring its connections with LA and playing with various data mining tools used in both communities.\nWeek 6 Readings  Baker, R. S., \u0026amp; Inventado, P. S. (2014). Educational Data Mining and Learning Analytics. In J. A. Larusson \u0026amp; B. White (Eds.), Learning Analytics: From Research to Practice (pp. 61–75). New York, NY: Springer New York. Slater, S., Joksimović, S., Kovanovic, V., Baker, R. S., \u0026amp; Gasevic, D. (2017). Tools for Educational Data Mining: A Review. Journal of Educational and Behavioral Statistics, 42(1), 85–106.  To make some of your annotations more useful for FROG activities, you can consider the following when making annotations this week:\n Consider ideas that are helpful for growing your general knowledge of learning analytics, and tag them with GoodPoints Consider ideas that are helpful for a specific project of yours, and tag them with UsefulPoints Consider annotating \u0026ldquo;muddy points\u0026rdquo; in an article that you want to know more about, and tag them with MuddyPoints  Note: These tags need to used accurately, e.g., not good points or GoodPoint, in order to be nicely aggregated by Hypothes.is.\nHousekeeping for Formal Participation Since we\u0026rsquo;ve finalized our Working Group and Special Interest Group plans, please create channels on Slack and invite group members in.\nLet the party begin!\n","date":1538974800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538974800,"objectID":"ec3de8400171ab3b16712261ce128d84","permalink":"https://colig.github.io/laumn/post/week6/","publishdate":"2018-10-08T00:00:00-05:00","relpermalink":"/laumn/post/week6/","section":"post","summary":"A brief introduction to Educational Data Mining (EDM) as a sister field of LA, as well as popular EDM tools.","tags":["EDM","Techniques"],"title":"Week 6: Educational Data Mining: An Overview","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" In this week, we will extend our dialogues on learning theory in Week 4 into deeper conversations about hidden assumptions in learning analytics.\nThis line of thinking has been informed by a talk given by Simon Knight at LAK13 titled Epistemology, Pedagogy, Assessment and Learning Analytics (see slides below). Their work has evolved over the years and one reading for this week is a book chapter with a set of provocations pushing us to think more about hidden assumptions.\n I\u0026rsquo;ve written about this topic as well, but in Chinese. To me, \u0026ldquo;Learning Analytics is like an iceberg. Its visible parts include materialized tools and observable activities, while its hidden parts comprise conceptualizations of learning, power relations in teaching and learning, and complex social, political and cultural intentions of education.\u0026rdquo; Catering to the Chinese audience, I drew on the etymology of the character 数 (\u0026ldquo;number\u0026rdquo;) in Chinese and explained how one of its ancient forms (below) is embedded with the meaning of punishing a woman for her \u0026ldquo;mistakes\u0026rdquo;. I could not stop asking: to what extent is this original meaning still reflected in our use of numbers or data (数据) today? Which other assumptions and biases are built into our daily data practices in general and learning analytics in particular?\nWeek 5 Readings  Knight \u0026amp; Buckingham Shum. (2017). Handbook of Learning Anlaytics, Chpater 1. Perrotta, C., \u0026amp; Williamson, B. (2018). The social life of Learning Analytics: cluster analysis and the “performance” of algorithmic education. Learning, Media and Technology, 43(1), 3–16.  To make some of your annotations more useful for FROG activities, you can consider the following when making annotations this week:\n Consider ideas that are helpful for growing your general knowledge of learning analytics, and tag them with GoodPoints Consider ideas that are helpful for a specific project of yours, and tag them with UsefulPoints Consider annotating \u0026ldquo;muddy points\u0026rdquo; in an article that you want to know more about, and tag them with MuddyPoints  These prompts are proposed in response to feedback we discussed in Week 4. Feel free to leave any thoughts as we\u0026rsquo;ve been doing in the class.\nHousekeeping Please finalize your Working Group and Special Interest Group choices. Feel free to ask questions on Slack.\n","date":1538370000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1538370000,"objectID":"f0a73bd2f28bd0e31922ad46c3e20578","permalink":"https://colig.github.io/laumn/post/week5/","publishdate":"2018-10-01T00:00:00-05:00","relpermalink":"/laumn/post/week5/","section":"post","summary":"Learning analytics is like an iceberg, with a myriad of assumptions hidden under the water.","tags":["Theory"],"title":"Week 5: Hidden Assumptions: Epistemology, Pedagogy, and Assessment","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Learning analytics are about learning, so theories of learning should not be ditched despite the data deluge that has been fueling the growth of learning analytics. Since the dawn of the field, there have been voices arguing for the importance of learning theory in the design, development, and implementation of learning analytics. In 2015, a special section was published by the Journal of Learning Analytics on the relation between learning theory and learning analytics. In the guest editorial, Wise and Shaffer (2015, p. 5) write:\n It is an exhilarating and important time for conducting research on learning, with unprecedented quantities of data available. There is danger, however, in thinking that with enough data, the numbers speak for themselves. In fact, with larger amounts of data, theory plays an ever-more critical role in analysis.\n The notion that theory matters even more in \u0026ldquo;big data\u0026rdquo; research in education goes against what was proposed in a controversial Wired article titled \u0026ldquo;The end of theory: The data deluge makes the scientific method obsolete\u0026rdquo; (Anderson, 2008). Now there is little disagreement that learning theory is essential for learning analytics.\nBriefly speaking, there are essentially two ways theory is important for the field of learning analytics.\n1. Theory Use in Learning Analytics As a field of research and practice, learning analytics work naturally draws from all sorts of theories. As summarized by Wise and Shaffer (2015, p. 9):\n Theory gives a researcher guidance about which variables to include in a model Theory gives a researcher guidance about what potential confounds, subgroups, or covariates in the data to account for Theory gives a researcher guidance as to which results to attend to Theory gives a researcher a framework for interpreting results Theory gives a researcher guidance about how to make results actionable Theory helps a researcher generalize results to other contexts and populations  For example, self-regulated learning (SRL) is widely used in learning analytics and MOOC research. SRL as a learning theory has informed data collection, data transformation, data mining, and result interpretation.\n2. Theory Building in Learning Analytics Even more exciting to me is the possibility of building new theories of learning and teaching, based on fine-grained data analysis enabled by advanced computational methods. Learning analytics and educational data mining research could give rise to new theories. For example, whether keystroke analysis can shed light on our understanding of writing processes? Whether temporal analysis can uncover \u0026ldquo;productive\u0026rdquo; patterns of collaborative discourse?\nEqually valuable are theories of learning analytics usage in emerging socio-technical contexts. For example, as new learning analytics tools are put in the hands of instructors to aid their pedagogical decisions, domain theories of analytics use can be created (e.g., van Leeuwen, 2015).\nWeek 4 Readings This week\u0026rsquo;s readings speak in particular to theory use in learning analytics. Reading #1 is a guest editorial on temporal analysis of learning data, which discusses four critical issues that are applicable to all learning analytics work. Reading #2 provides a concrete example of using a well-established learning theory (self-regulated learning in this case) in a research study. Reading #3 (optional) is the controversial Wired article mentioned above.\n Chen, B., Knight, S., \u0026amp; Wise, A. F. (2018). Critical Issues in Designing and Implementing Temporal Analytics. Journal of Learning Analytics, 5(1), 1–9. (Note: Only Sections 3-4 (pp. 3-7) are required. This reading can only be annotated offline. Check this Youtube video to learn how.) Kizilcec, R. F., Pérez-Sanagustín, M., \u0026amp; Maldonado, J. J. (2017). Self-regulated learning strategies predict learner behavior and goal attainment in Massive Open Online Courses. Computers \u0026amp; Education, 104, 18–33. Optional: Anderson, 2008, The End of Theory: The Data Deluge Makes the Scientific Method Obsolete  When reading each required article, please create at least 1 annotation and reply to 2 annotations made by peers. When interacting with Reading #2, please note how the self-regulated learning theory was applied in the study.\nMeet Learning Analytics Experts Dr. Alyssa Wise is Associate Professor of Learning Sciences and Educational Technology and the Director of the Learning Analytics Research Network at NYU. She is an Editor in Chief of the Journal of Learning Analytics and an Associate Editor of the Journal of the Learning Sciences. According to her bio, \u0026ldquo;Dr. Wise\u0026rsquo;s research is situated at the intersection of the learning sciences and educational data science, focusing on the design of learning analytics systems that are theoretically grounded, computationally robust, and pedagogically useful for informing teaching and learning.\u0026rdquo; Among many wise things shared by Dr. Wise, below is a recent video clip of her talking about what we need to be successful in the field of learning analytics.\n Dr. David Williamson Shaffer is the Vilas Distinguished Professor of Learning Sciences at the University of Wisconsin-Madison. He is known for his work on game-based learning and Epistemic Network Analysis. Below is a keynote speech he delivered at the 2018 Learning Analytics and Knowledge conference in Sydney, where he summarized his idea of \u0026ldquo;quantitative ethonography\u0026rdquo; and ways to tackle theory scarcity in the age of \u0026ldquo;big data.\u0026rdquo;\n Housekeeping Please continue to explore and articulate your Working Group project ideas. Please consider problems/goals, stakeholders, data sources, analysis, and action of your group project.\nPlease consolidate your Special Interest Group (SIG) choice. Feel free to ask questions on Slack if you\u0026rsquo;re unsure about any SIG topics.\n","date":1537765200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537765200,"objectID":"02330958f979bbbbc751fd4593fa52ce","permalink":"https://colig.github.io/laumn/post/week4/","publishdate":"2018-09-24T00:00:00-05:00","relpermalink":"/laumn/post/week4/","section":"post","summary":"Learning analytics are about learning, so theories of learning should not be ditched despite the data deluge that has been fueling the growth of learning analytics.","tags":["Theory"],"title":"Week 4: Theory and Learning Analytics","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Let\u0026rsquo;s be clear, ethics should not be an after-thought in a learning analytics application. But what do ethical practices in the field entail is not always clear.\nWhile research ethics considers principles such as confidentiality, privacy, and informed consent, a learning analytics project may not be considered research at all (if its goal is not to produce generalizable knowledge). However, expansive collection of learning data, increasing cases of \u0026ldquo;black-box algorithms,\u0026rdquo; and more direct impact on learners necessitate some serious conversations about ethics in learning analytics.\nLast week\u0026rsquo;s discussions have already touched upon many questions about ethics. This week, we are going to dive into ethics, algorithmic accountability, and system integrity.\nWeek 3 Readings  Prinsloo, P., \u0026amp; Slade, S. (2017). Ethics and Learning Analytics: Charting the (Un)Charted. In C. Lang, G. Siemens, A. Wise, \u0026amp; D. Gasevic (Eds.), Handbook of Learning Analytics (Chapter 4, pp. 49–57). Society for Learning Analytics Research (SoLAR). (Note: It may be difficult to highlight larger text snippets in this particular PDF file.) Optional: Geiger, R. S. (2017). Beyond opening up the black box: Investigating the role of algorithmic systems in Wikipedian organizational culture. Big Data \u0026amp; Society, 4(2), 2053951717730735.  When reading each article, please create at least 1 annotation and reply to 2 annotations made by peers.\nMeet Learning Analytics Experts Paul Prinsloo from the University of South Africa (Unisa) has been writing and giving talks about \u0026lsquo;ethics and learning analytics\u0026rsquo; for many years. He has recently delivered a keynote on this topic in Scotland. He has graciously allowed me to embed his slides on our course website:\nZombie categories, broken data and biased algorithms: What else can go wrong? Ethics in the collection, analysis and use of student data  \nSimon Buckingham Shum, Director of the Connected Intelligence Centre (CIC) at the University of Technology Sydney, invited us to consider \u0026lsquo;Algorithmic Accountability\u0026rsquo; and \u0026lsquo;Analytic System Integrity\u0026rsquo;. Discussion of Algorithmic Accountability has been taken up by important academic associations like the Association for Computing Machinery (ACM). But Simon stretches our thinking to consider \u0026lsquo;Analytic System Integrity\u0026rsquo; in learning analytics. Below is a talk he gave at the UCL Institute of Education in 2016. His team is recently working on Ethical Design Critique, which offers concrete measures to enhance ethics in learning analytics tools.\n Housekeeping Please continue to explore and articulate your Working Group project ideas. Please consider problems/goals, stakeholders, data sources, analysis, and action of your project. Continue to comment on each other\u0026rsquo;s ideas on Slack and don\u0026rsquo;t be shy about saying \u0026ldquo;Our ideas are like cousins. Let\u0026rsquo;s team up.\u0026rdquo;\nPlease start to consider which Special Interest Group(s) you\u0026rsquo;re interested in. Below is a list of tentative topics but you can suggest topics beyond the list. Ideally, the Special Interest Group you sign up for is related to your Working Group project.\n Social Network Analysis Predictive Models Text and Discourse Analytics Visual Learning Analytics Temporal Analytics Institutional Readiness  Finally, whenever there is any interesting article, please either annotate or share via Slack.\n","date":1537074000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537074000,"objectID":"360c0e50cc89c96df36cf579c9b69617","permalink":"https://colig.github.io/laumn/post/week3/","publishdate":"2018-09-16T00:00:00-05:00","relpermalink":"/laumn/post/week3/","section":"post","summary":"Ethics, algorithmic accountability, and system integrity in learning analytics","tags":["Ethics","Algorithmic Accountability"],"title":"Week 3: Ethics, Algorithmic Accountability, and System Integrity","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" Thanks for the engaged conversations in the first week of #LAUMN!\nWe\u0026rsquo;ve been engaged in such thoughtful dialogues via Hypothes.is annotations. We\u0026rsquo;re trying to survive all those acronyms by maintaining a community glossary. Also a big shout-out to Crystal Rose-Wainstock for her #LAUMN tweet about ethics in learning analytics (below). The breadth of expertise represented in our community is truly energizing. I hope we can continue to have deep conversations within and beyond this community, and to engage in learning that\u0026rsquo;s personal to everyone of us.\nThinking about learning analytics and the ethics of big data use in education. #laumn #ci5371 pic.twitter.com/8wQgpH0OF5\n\u0026mdash; Crystal Rose-Wainstock (@crosewainstock) September 5, 2018 \nIn the spirit of \u0026ldquo;living and exploring the capacity of learning analytics,\u0026rdquo; I want to introduce an analytics tool named CROWDLAAERS developed by my UC-Denver colleagues Remi Kalir and Francisco Perez for the Marginal Syllabus project. This application, which just came out during the summer, retrieves annotations from the server and generates interesting interactive visualizations.\nFor instance, below is an overview of our own #LAUMN annotation threads. I found it quite useful for discovering threads with more (or less) participation.\nAnother example is the calendar view that tells us when we tend to make annotations.\nIt appears we were quite busy making annotations during the weekend. I believe we can do better next week \u0026ndash; working less during the weekend if possible ;-)\nWeek 2 This week we will:\n Develop a stronger grasp of the field of LA Start to explore Working Group project ideas  Video After reading and discussing the George Siemens (2013) article during Week 1, it\u0026rsquo;s worthwhile to watch a lecture George gave to a MOOC (massive open online course) on learning analytics. George is the founding president of the Society for Learning Analytics Research (SoLAR), which is the most prominent international organization of learning analytics.\n Readings This week, we will get a chance to take a closer look at this field by exploring more cases/examples and posing more questions. What problems do learning analytics seek to address? In which educational settings? At which levels of an education system? Because this field is truly inter- and trans-disciplinary, I expect us to enter this field from our unique backgrounds and contribute to the field with different perspectives.\n Buckingham Shum, S. (2012). UNESCO Policy Brief: Learning Analytics. UNESCO Institute for Information Technologies in Education. Choose one from below (Note: #1 is open-access, and #2 is accessible to UMN colleagues):  Bienkowski, M., Feng, M., \u0026amp; Means, B. (2012). Enhancing Teaching and Learning Through Educational Data Mining and Learning Analytics: An issue brief (pp. 1-35). U.S. Department of Education Office of Educational Technology. Krumm, A., Means, B., \u0026amp; Bienkowski, M. (2018). Learning Analytics Goes to School: A Collaborative Approach to Improving Education, Chapter 2. Routledge. (Note: This reading can only be annotated offline. Check this Youtube video to learn how.)   When reading each article, please create at least 1 annotation and reply to 2 annotations made by peers. Let the community know when you find a case that matches perfectly with your interests, stretches your imagination of learning anlaytics, or concerns you for whatever reasons.\nReminder: If you are a UMN participant, when annotating with Hypothes.is, please make sure the LAUMN group is selected.\nExploring Working Group project ideas While/after reading, draft a project idea based on your interests and post it on Slack. This is an opportunity for us to learn more about our interests and form project teams. So please comment on each other\u0026rsquo;s posts if you\u0026rsquo;re also interested or have questions/suggestions.\nFor open participants, please tweet a blog post (or a shared Google doc) using the #LAUMN hashtag.\nBelow are a list of example project ideas. Please see the syllabus for more detailed guidelines.\n Applying Natural Language Processing to Investigating Language Development and Epistemic Complexity in Group Chats Integrating a Teacher Dashboard in K-12: A Mixed-Methods Study of Teacher Perspectives \u0026ldquo;Burn the World\u0026rdquo; Learning Analytics Design (Note: Burn the World is a game for environmental education.) \u0026ldquo;The Bridge\u0026rdquo;: An Analytics Tool to Integrate Community Knowledge on StackOverflow in RStudio Developing a Deep Learning Model for the Prediction of Student Success in Introductory Physics  Virtual Meeting Our second virtual meeting will take place on Monday, 09/17, 5-6:30pm via Zoom. You will receive a Calendar invitation with details.\nSee you soon!\n","date":1536555600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536642000,"objectID":"5999033742e12cfc5b155986d8daa287","permalink":"https://colig.github.io/laumn/post/week2/","publishdate":"2018-09-10T00:00:00-05:00","relpermalink":"/laumn/post/week2/","section":"post","summary":"What problems does learning analytics seek to address? In which educational settings? At which levels of an education system?","tags":["Overview","Video"],"title":"Week 2: Learning Analytics: A Brief Overview","type":"post"},{"authors":[],"categories":null,"content":" ","date":1536210000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536210000,"objectID":"e8eef06b575f2e199c6a1b20456e1ccd","permalink":"https://colig.github.io/laumn/post/glossary/","publishdate":"2018-09-06T00:00:00-05:00","relpermalink":"/laumn/post/glossary/","section":"post","summary":"A crowd-sourced glossary of the community.","tags":["Glossary"],"title":"Glossary","type":"post"},{"authors":["Bodong Chen"],"categories":null,"content":" A warm welcome to CI 5371 - Learning Analytics: Theory and Practice! This course has been taught twice by myself at the University of Minnesota (in 2015 and 2016). This is the first time this course is offered fully online as a formal (non-special topics) course. As the instructor, I look forward to our adventure together this semester!\nThis week we will:\n Get familiar with the course, including its design, schedule, and tools Get to know each other Read an introductory article Discuss our diverse interests in learning analytics  The Course Syllabus First thing first, please read the course syllabus (http://bit.ly/lamn-syl) in its entirety. Leave a Hypothesis annotation or send me an email when you have any questions.\nTechnology setup An online course does not need to be about watching videos and answering quizzes. To foster rich learning experiences, we will be using several technological tools to foster social, collaborative learning. Depending on your familiarity with these tools, there could be a learning curve. So please spend time this week to familiarize yourself with them.\nZoom. We will host virtual meetings on Zoom. Please make sure your computer has Zoom installed (see the video below). Please test your Zoom setup in advance to make sure audio and video configurations work properly. You will receive a calendar invitation with details about joining our Zoom meetings.\n Slack. You will receive a link that invites you to join our Slack community. Course announcements are made on Slack. All sorts of class discussion will take place there as well. First time using Slack? Watch the video below and/or read this brief introduction to Slack.\n Hypothes.is. If you\u0026rsquo;re a formal participant, you should have received a link that invites you to join our Hypothes.is group. Hypothes.is is a web annotation tool that enables us to discuss readings in a contextual manner. When annotating, please make sure our group name (LAUMN) is properly selected. See this page to get started, and this page to learn about annotating together as a group.\nTwo tracks of participation This course website is openly available, allowing two tracks of participation designed for this class.\n UMN class: For UMN graduate students enrolled in the class, your participation in this class is not that different from taking another online class. You are expected to meet course requirements outlined in the course syllabus. You will have private spaces (on Slack and Hypothesis private group) for within-class communications. You can decide the extent to which you interact with colleagues outside of the class list. Open participation: For \u0026lsquo;Open Participants\u0026rsquo; who would like to follow along, you can access the same materials curated on this website. Because 90% of course readings are open-access, you will be able to annotate readings using Hypothes.is as well (using the LAUMN tag). You are also encouraged to interact with me and community members via Twitter hashtag #LAUMN.  If you have any feedback on the design, I\u0026rsquo;d love to hear your thoughts.\nWeek 1 Readings  Course syllabus Siemens, G. (2013). Learning analytics: The emergence of a discipline. The American Behavioral Scientist, 57(10), 1380–1400. (Downloadable PDF for Open Participants.)  When reading Siemens (2013), please create at least 1 annotation and reply to 2 annotations made by peers. Not sure what/how to annotate, consider sentence starters like: \u0026quot;I'm intrigued by...\u0026quot;, \u0026quot;I'm surprised by...\u0026quot;, \u0026quot;I need to understand...\u0026quot;, \u0026quot;Additional resource...\u0026quot;, etc.\nTip: Click on the Annotations link to the top of this page to see all annotations posted to our Hypothes.is group.\nVirtual Meeting Our first virtual meeting will take place on Monday, 09/10, 5-6:30pm via Zoom. You will receive a Calendar invitation with details.\nSee you soon!\n","date":1535518800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535950800,"objectID":"9f2799f01ef07323bca16fbf22a3bd29","permalink":"https://colig.github.io/laumn/post/week1/","publishdate":"2018-08-29T00:00:00-05:00","relpermalink":"/laumn/post/week1/","section":"post","summary":"Getting started with CI 5371.","tags":["Introduction"],"title":"Week 1: Introduction","type":"post"},{"authors":[],"categories":null,"content":" ","date":1533099600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1533099600,"objectID":"d05a050b8b35b6f1eedc60980c7a79e5","permalink":"https://colig.github.io/laumn/post/annotations/","publishdate":"2018-08-01T00:00:00-05:00","relpermalink":"/laumn/post/annotations/","section":"post","summary":"Web annotations made by the community.","tags":["Tools","hide"],"title":"Web Annotations","type":"post"}]